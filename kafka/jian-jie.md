---
description: '本文章由olinex翻译, 转载请在页面开头标明出处'
---

# 简介

阿帕奇 Kafka 是一个分布式流处理系统

一个流处理系统主要有三个能力:

1. 发布和订阅记录流, 类似于消息队列和企业邮件系统
2. 以容错-持久地方式存储记录流
3. 当记录流出现时处理它

Kafka通常用于以下两种应用:

1. 在系统或应用之间构建一个能够可靠地获取实时数据流地管道
2. 构建一个实时流应用能够转换或响应数据流

为了能够理解Kafka究竟是如何实现的, 让我们从最底层了解它的能力.

首先让我们定义以下几个概念:

* Kafka 可以作为集群应用在一个或多个数据中心服务器上
* Kafka 集群可以将记录流以 "topic" \( 主题 \) 的形式按分类存储
* 每个记录通过 键, 值, 时间戳 来存储

Kafka有四类核心API:

* 生产者API - 允许应用在一个或多个主题上发布记录流
* 订阅者API - 允许应用在一个或多个主题上订阅, 并处理发布给他们的记录流
* 流API - 允许应用作为流处理者, 消费一个或多个主题上的输入流, 并向一个或多个主题生产输出流, 能有效地将输入流转换为输出流
* 连接器API - 允许构建并运行可重用的生产者或消费者, 通过连接Kafka的主题至已存在的应用或数据系统. 例如, 连接相关数据库的连接器会捕捉数据表的每一次改变.

![&#x6765;&#x6E90;&#x4E8E;&#x5B98;&#x65B9;&#x6587;&#x6863;\(https://kafka.apache.org/documentation/\#introduction\)](../.gitbook/assets/kafka-apis.png)

Kafka的客户端和服务器是通过一种简单, 高效, 语言无关的TCP协议来进行连接的. 这种协议已经进行版本控制, 并且向下兼容. 我们提供了Java版本的Kafka客户端, 不过同样有很多别的语言地客户端可以使用.

## 主题和日志

让我们深入理解记录流地核心概念 - 主题.

主题是推送记录的分类. 在Kafka内, 主题经常有多个订阅者. 这意味着, 主题可以有零到多个消费者在订阅写入主题地数据.

对于每个主题, Kafka集群会维护一个分区日志:

![&#x6765;&#x6E90;&#x4E8E;&#x5B98;&#x65B9;&#x6587;&#x6863;\(https://kafka.apache.org/documentation/\#introduction\)](../.gitbook/assets/log_anatomy.png)

每个分区都是一个有序的, 不可变的记录序列, 这些记录不断被追加到一个结构化的提交日志中. 分区中的记录都被分配了一个名为偏移量的顺序 id , 该偏移量唯一标识分区中的每个记录.

Kafka在一个可配置的保留周期内持久地保存所有已发布地记录, 无论它们是否已经被消费. 例如, 保留周期设置为两天, 则在发布记录后的两天内, 它可供使用, 之后将被丢弃以释放空间. Kafka的表现是跟数据大小无关的, 因此可以长时间存储大量数据.

![&#x6765;&#x6E90;&#x4E8E;&#x5B98;&#x65B9;&#x6587;&#x6863;\(https://kafka.apache.org/documentation/\#introduction\)](../.gitbook/assets/log_consumer.png)

事实上, 每个消费者基本上只保存自身在日志内的偏移量或位置的元数据. 这个偏移量被消费者控制: 一般情况下, 消费者会线性地增加它的偏移量, 但事实上, 因为它的位置被消费者控制, 消费者可以按照任意顺序进行消费. 例如一个消费者可以重置为早先的偏移量, 来重新处理过去的数据, 或者可以跳到最新的记录, 并从 "现在" 开始消费.

这种功能的组合意味着Kafka的消费者非常的轻量. 这使得消费者的加入和退出, 对集群和其他消费者的影响非常小. 例如, 你可以使用我们的命令行工具来"跟踪"任意主题的内容, 而不需要修改任何正在运行的消费者.

日志的分区有多种用途. 首先, 它允许日志扩展到指定的大小来匹配单一的服务器. 每个独立的分区必须适合承载它的服务器, 不过一个主题可能拥有多个分区, 因此它可以处理任意数量的数据. 其次, 他们可以作为平行单位, 而不是独立的一份.

## 分布式

日志的分区分布在Kafka集群中的服务器上, 每个服务器处理数据并要求共享分区. 为了实现容错, 每个分区都在可配置的服务器数量之间进行复制。

每个分区都有一个主服务器和零至多个副服务器. 主服务器负责处理所有对分区的读写请求, 副服务器则被动地复制主服务器的行为. 如果主服务器不可用, 其中一个副服务器将自动变成新的主服务器. 每个服务器都将作为某些分区的主服务器和其他分区的副服务器, 因此在集群中, 负载将会被很好地分摊.

## 异地备援

Kafka MirrorMaker向集群提供了异地备缓功能. 通过MirrorMaker, 消息可以在多个数据中心或云块复制. 通过主动或被动的存储方案, 你可以使用这些消息来进行备份和恢复; 亦或者, 你可以将数据保存在更靠近用户的地方, 或者提供与位置相关的数据.

## 生产者

生产者主要负责将数据推送至所选的主题. 他负责决定记录所要保存的主题分区. 可以通过流行的简单调度轮询算法来进行负载均衡, 或可以通过别的语义分区算法 \( 语义指的是基于记录的关键词 \). 

## 消费者

消费者通过组名来为自身分组, 每个推送到主题的记录, 都将被交付给正在订阅该主题的消费者组中的一个消费者实例. 消费者可以是独立的进程或位于独立的服务器中.

如果所有的消费者都在同一个消费者组内, 记录会有效均衡地发送至消费者实例.

如果所有的消费者实例都在不同的消费者组内, 那么每个记录都将会被广播给所有的消费者进程.

![&#x6765;&#x6E90;&#x4E8E;&#x5B98;&#x65B9;&#x6587;&#x6863;\(https://kafka.apache.org/documentation/\#introduction\)](../.gitbook/assets/consumer-groups.png)

拥有两个服务器的Kafka集群承载这四个分区 \( P0 - P3 \), 并有两个消费者组. 组A有两个消费者实例, 组B有四个.

然而, 更常见的情况是, 每个主题拥有少量的消费者, 每个主题有一个"订阅者". 每个组由多个消费者构成, 有利于弹性伸缩和提高容错率. 使用消费者集群作为订阅者, 而不是单一进程, 对生产-消费模式而言再合适不过了.

在Kafka内, 消费的实现方案是通过为消费者实例分割日志分区, 因此每个实例都能公平地在任何时间独享分区. 组内的成员关系是通过Kafka的协议动态管理的. 如果新消费者实例加入一个组, 新的实例会从别的组内成员那里获取分区, 如果实例不可用, 它的分区将会被分发给剩余的消费者实例.

Kafka只提供记录在分区内顺序, 而不会提供同一主题中不同分区的顺序. 对于大多数应用而言, 通过键值获取分区的数据和对每个分区的排序已经足够使用. 然而, 如果需要对所有记录获取顺序, 可以只为主题分割一个分区来实现, 然而这意味着只有一个消费者组内只有一个消费者.

## 多租户

通过设置哪些主题可以产生或消费数据, 你可以将Kafka作为多租户技术的解决方案. 管理员可以对请求实施配额管理, 以控制客户端可以使用的资源.

## 保障

Kafka提供了以下保证:

* 生产者发送到特定主题分区的消息将按照其发送顺序保存. 也就是说, 如果记录M1和M2由同一个生产者发送, 并且首先发送M1, 则M1的偏移量小于M2, 并在日志中更早地出现.
* 消费者按照Kafka集群中日志的存储顺序读取记录.
* 对于复制因子为N的主题, 最多可以容忍N-1个服务器故障, 而不会丢失提交的任何记录.

## 用于消息队列

kafka的流概念与传统的消息队列相比有什么区别和优缺点呢?

传统上, 消息队列具有两种模式:

* 队列
* 发布-订阅

在队列模式中, 一组消费者可以从队列中读取数据, 但每条记录仅会进入其中一个消费者. 在发布-订阅模式中, 所有的消费者都会收到记录. 这连个模型都有各自的优缺点. 队列的优势在于, 你可以将数据处理分派到多个不同的消费者中, 从而扩展消费能力. 但由于每个记录只能被一个消费者处理, 因此不支持多租户. 而发布-订阅模式允许你将数据传给所有的消费者, 也因此无法扩展消费能力.

Kafka的消费者组模式囊括了这两个模式. 与队列模式类似, 消费者组使你能够将数据处理的工作拆分到一系列的进程中 \(消费者组的成员\). 与发布-订阅模式类似, Kafka允许你将消息广播到不同的消费者组内.

Kafka的优势在于, 每个主题都可以同时支持队列和发布-订阅模式, 而不是只能选择其中一个.

与传统的消息队列相比, Kafka具有更强的时序保证.

传统消息队列将记录按照顺序保存在服务器内, 如果多个消费者从队列中消费, 则队列将按照存储顺序分发记录. 尽管服务器按照顺序分发记录, 但是这些记录是异步传递给消费者的, 因此会乱序到达不同的消费者. 这意味着在并行的情况下将会丢失记录的顺序. 对于时序性要求严格的队列及其消费者而言, 通常通过**专用消费者**的方式来解决这个问题, 通过仅允许一个进程来消费队列, 但是这意味着无法并行处理.

Kafka在这方面做的很好. 通过在主题内区分具有并行性的分区, Kafka能够在消费者组范围内保证时序性和负载均衡. 这是通过将主题中的分区分配给消费者组中的消费者来实现的, 以实现每个分区都由组中的一个消费者独立消费. 这样做我们给能确保消费者是该分区的唯一处理者, 并按照顺序消费数据, 同时通过多个分区, 仍然能够平衡多个消费者的负载, 但是请注意, 消费者组内的组员不能超过分区的数量.

## 用于存储

任何允许发布与消费解耦的消息队列, 都可以有效地作为实时消息的存储系统. Kafka的不同之处在与它是一个很好的存储系统. 写入Kafka集群的数据将写入磁盘并进行复制以实现容错. Kafka允许生产者等待写入确认, 以便直到副本完全复制完成. 即使写入失败的服务器也能够保留写入, 写入才被认为是完整的.

Kafka的磁盘结构可以很好地扩展, 无论是50KB还是50TB的持久数据, Kafka的性能都能保持一致.

认真对待存储并允许客户端控制读取位置的结果就是, 你可以将Kafka视为一种 高性能 低延迟提交 具有副本复制和传播功能的专业日志存储系统.

## 用于流处理

在Kafka中, 流处理是指从**输入主题**中获取连续数据流, 进行处理后生成连续的输出数据流至输出主题中.

例如, 零售应用程序可以接受销售和发货的输入流, 并输出根据数据计算出的新订购和价格调整流.

我们当然可以直接使用生产者和消费者的API进行简单处理, 但是, 对于更加复杂的转换, Kafka提供了完全集成的Streams API. 这些API允许我们构建一些非凡的应用, 能够将数据流聚合并连接在一起.

这个功能有助于解决应用程序所面临的难题: 处理无序数据时, 在代码更改时重新处理输入, 执行状态运算等.

Stream API建立在Kafka提供的核心功能之上: 它使用生产者和消费者API作为输入输出, 使用Kafka进行状态存储, 通过消费者组机制实现消费者实例之间的容错.



