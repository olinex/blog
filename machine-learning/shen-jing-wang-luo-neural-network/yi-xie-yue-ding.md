---
description: '本文章由olinex原创, 转载请在页面开头标明出处'
---

# 一些约定

## 层数

神经网络一般至少含有三个层次, 我们约定输入层的层数为0, 使用字母j来表示

## 序数

神经网络输入层和隐藏层都会有多个单元, 我们约定它们的第一个单元为偏置单元, 其序数为0, 使用字母i来表示序数.

## 权重

神经网络中, 每个逻辑单元都有各自的权重向量W, 因此第j层的第i个单元的权重向量W表示为:

$$
\vec{W}_i^{(j)} = 
\left [
\begin{matrix}
w_{i0}^{(j)} \\
w_{i1}^{(j)}\\
...\\ 
w_{in}^{(j)}
\end{matrix}
\right ]
$$

输入层并没有权重, 因此权重的j &gt; 0 . 同时因为每一层隐藏层的第一个单元为数字单元, 因此权重向量的i &gt; 0.

## 激励值

激励值即自变量向量X通过激励函数s计算后得到的数值, 和因变量y在意义上是等价的. 那为什么还要多余定义一个激励值呢? 这更多地是为了表述的方便, 因为因变量y的含义在很多范畴上都存在. 为了仅针对神经网络隐藏层中逻辑单元的激励函数s计算出的过程值, 我们定义了激励值, 并用a来表述, 并定义激励值向量A:

$$
\vec{A}^{(j)} = 
\left [
\begin{matrix}
a_0^{(j)}\\
a_1^{(j)}\\
...\\
a_n^{(j)}
\end{matrix}
\right ]\\

\vec{A}^{(0)} = \vec{X}\\
$$

需要注意的是, 神经网络每一层单元的个数都不是固定的, 也因此每个逻辑单元权重向量W的元素个数, 事实上取决于上一层单元的个数. 我们假设激励值向量A内元素的个数为n, 并不是代表不同层次的逻辑单元的权重个数相等, 也不代表权重个数与特征向量X的维度相等. 仅有第一层隐藏层的逻辑单元的权重向量W的元素个数与特征向量X的维度相关.

对于第一层隐藏层而言:

$$
a_i^{(1)} = s(\vec{W}_{i}^{(1)} \cdot \vec{A}^{(0)})
$$

$$
a_1^{(1)} = s(\vec{W}_{1}^{(1)} \cdot \vec{X})\\
= s(
w_{10}^{(1)}x_0 + 
w_{11}^{(1)}x_1 + 
w_{12}^{(1)}x_2 + 
... + 
w_{1n}^{(1)}x_n
)
$$

对于后续隐藏层而言:

$$
a_i^{(j)} = s(\vec{W}_{i}^{(j)} \cdot \vec{A}^{(j-1)})
$$

$$
a_1^{(2)} = s(\vec{W}_{1}^{(2)} \cdot \vec{A}^{(1)})\\
= s(
w_{10}^{(2)}a_0^{(1)} + 
w_{11}^{(2)}a_1^{(1)} +
w_{12}^{(2)}a_2^{(1)} +
... +
w_{1n}^{(2)}a_n^{(1)}
)
$$

