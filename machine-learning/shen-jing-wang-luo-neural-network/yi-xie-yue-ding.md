---
description: '本文章由olinex原创, 转载请在页面开头标明出处'
---

# 一些约定

## 网络层数

神经网络具有多个层次, 我们用字母L表示神经网络的网络层数.

神经网络一般至少含有三个层次, 我们约定输入层的网络层数为1

## 单元序数

神经网络每一层都可能有多个单元, 我们约定每一层除了偏置单元外的单元个数为单元序数, 使用字母S来表示. 需要注意的是, 神经网络中, 每一层的单元个数都可以指定. 而输入层的单元个数与特征向量的维度相等, 输出层的单元个数与输出值y的分布有关:

$$
S_1 = n
$$

当使用神经网络表征线性回归问题或二项分布的逻辑回归问题时:

$$
S_{L} = 1
$$

当使用神经网络表征多项分布的逻辑回归问题时:

$$
S_{L} = K
$$

其中K为多项分布的项数, 因此K必然大于2.

## 权重

神经网络中, 每个逻辑单元都有各自的权重向量W, 因此第l层的第i个单元的权重向量W表示为:

$$
W_i^{(l)} = 
\left [
\begin{matrix}
w_{i0}^{(l)} \\
w_{i1}^{(l)}\\
...\\ 
w_{iS_{(l-1)}}^{(l)}
\end{matrix}
\right ]
$$

其中, S\(l - 1\)为上一层的单元序数. 输入层并没有权重, 因此权重的l &gt; 1 .

## 激励值

激励值即自变量向量X通过激励函数g计算后得到的数值, 和因变量y在意义上是等价的. 那为什么还要多余定义一个激励值呢? 这更多地是为了表述的方便, 因为因变量y的含义在很多范畴上都存在. 为了仅针对神经网络隐藏层中逻辑单元的激励函数g计算出的过程值, 我们定义了激励值, 并用a来表述, 并定义激励值向量A:

$$
A^{(l)} = 
\left [
\begin{matrix}
a_0^{(l)}\\
a_1^{(l)}\\
...\\
a_{S_{l}}^{(l)}
\end{matrix}
\right ]\\

A^{(1)} =X\\
$$

需要注意的是, 神经网络每一层单元的个数都不是固定的, 也因此每个逻辑单元权重向量W的元素个数, 事实上取决于上一层单元的个数.

对于第一层隐藏层的第i个单元而言:

$$
a_i^{(2)} = 
g(W_{i}^{(2)} \cdot A^{(1)}) = 
g(W_{i}^{(2)} \cdot X)\\
= g(
w_{i0}^{(2)}x_0 + 
w_{i1}^{(2)}x_1 + 
w_{i2}^{(2)}x_2 + 
... + 
w_{in}^{(2)}x_n
)\\
=g(\sum_{j=0}^{S_1}w_{ij}^{(2)}x_j)
$$

对于后续第j层的第i个逻辑单元而言:

$$
a_i^{(l)} = g(W_{i}^{(l)} \cdot A^{(l-1)})\\
= g(
w_{i0}^{(l)}a_0^{(l-1)} + 
w_{i1}^{(l)}a_1^{(l-1)} +
w_{i2}^{(l)}a_2^{(l-1)} +
... +
w_{i{S_{(l-1)}}}^{(l)}a_{S_{(l-1)}}^{(l-1)}
)\\
=g(\sum_{j=0}^{S_{(l-1)}}w_{ij}^{(l)}a_j^{(l-1)})
$$



